{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ae012f",
   "metadata": {},
   "source": [
    "# The ScikitLearn.jl library\n",
    "\n",
    "The Scikit-learn library is an open source machine learning library developed for the Python programming language, the first version of which dates back to 2010. It implements a large number of machine learning models, related to tasks such as classification, regression, clustering or dimensionality reduction. These models include Support Vector Machines (SVM), decision trees, random forests, or k-means. It is currently one of the most widely used libraries in the field of machine learning, due to the large number of functionalities it offers as well as its ease of use, since it provides a uniform interface for training and using models. The documentation for this library is available at https://scikit-learn.org/stable/.\n",
    "\n",
    "For Julia, the ScikitLearn.jl library implements this interface and the algorithms contained in the scikit-learn library, supporting both Julia's own models and those of the scikit-learn library. The latter is done by means of the PyCall.jl library, which allows code written in Python to be executed from Julia in a transparent way for the user, who only needs to have ScikitLearn.jl installed. Documentation for this library can be found at https://scikitlearnjl.readthedocs.io/en/latest/.\n",
    "\n",
    "As mentioned above, this library provides a uniform interface for training different models. This is reflected in the fact that the names of the functions for creating and training models will be the same regardless of the models to be developed. In the assignments of this course, in addition to ANNs, the following models available in the scikit-learn library will be used:\n",
    "\n",
    "- Support Vector Machines (SVM)\n",
    "- Decision trees\n",
    "- kNN\n",
    "\n",
    "In order to use these models, it is first necessary to import the library (using ScikitLearn, which must be previously installed with\n",
    "\n",
    "```Julia\n",
    "import Pkg;\n",
    "Pkg.add(\"ScikitLearn\"))\n",
    "```\n",
    "\n",
    "The scikit-learn library offers more than 100 types of  different models. To import the models to be used, you can use @sk_import. In this way, the following lines import respectively the first 3 models mentioned above that will be used in the practices of this subject:\n",
    "\n",
    "```Julia\n",
    "@sk_import svm: SVC\n",
    "@sk_import tree: DecisionTreeClassifier\n",
    "@sk_import neighbours: KNeighborsClassifier\n",
    "```\n",
    "\n",
    "When training a model, the first step is to generate it. This is done with a different function for each model. This function receives as parameters the model's own parameters. Below are 3 examples, one for each type of model that will be used in these course assignments:\n",
    "\n",
    "```Julia\n",
    "model = SVC(kernel=\"rbf\", degree=3, gamma=2, C=1);\n",
    "model = DecisionTreeClassifier(max_depth=4, random_state=1);\n",
    "model = KNeighborsClassifier(3);\n",
    "```\n",
    "\n",
    "An explanation of the parameters accepted by each of these functions can be found in the library documentation. In the particular case of decision trees, as can be seen, one of these parameters is called `random_state`. This parameter controls the randomness in a particular part of the tree construction process, namely in the selection of features to split a node of the tree. The Scikit-Learn library uses a random number generator in this part, which is updated with each call, so that different calls to this function (together with its subsequent calls to the `fit!` function) to train the model will result in different models. To control the randomness of this process and make it deterministic, it is best to give it an integer value as shown in the example. Thus, the creation of a decision tree with a set of desired inputs and outputs and a given set of hyperparameters is a deterministic process. In general, it is more advisable to be able to control the randomness of the whole model development process (cross-validation, etc.) by means of a random seed that is set at the beginning of the whole process.\n",
    "\n",
    "Once created, any of these models can be adjusted with the `fit!` function.\n",
    "\n",
    "### Question\n",
    "\n",
    "What does the fact that the name of this function ends in bang (!) indicate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b8524",
   "metadata": {},
   "source": [
    "`The exclamation mark (!) at the end of a function name signifies that the function changes the object it operates on directly, rather than creating a new version of that object.`\n",
    "\n",
    "`It means that the model received as parameter is modified inside the function`\n",
    "\n",
    "`For example, the fit! function updates a machine learning model in place, modifying the original model instead of producing a new one. This approach can improve memory usage and performance because it avoids duplicating data unnecessarily.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5151f1",
   "metadata": {},
   "source": [
    "Contrary to the Flux library, where it was necessary to write the ANN training loop, in this library the loop is already implemented, and it is called automatically when the `fit!` function is executed. Therefore, it is not necessary to write the code for the training loop.\n",
    "\n",
    "### Question\n",
    "\n",
    "As in the case of ANNs, a loop is necessary for training several models. Where in the code (inside or outside the loop) will you need to create the model? Which models will need to be trained several times and which ones only once? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7437a0",
   "metadata": {},
   "source": [
    "`The model has to be created inside the loop, to have several models.`\n",
    "\n",
    "`Deterministic models, such as decision trees, k-nearest neighbors (KNN), and support vector machines (SVM), are generally trained only once since their training processes produce the same results given the same inputs and parameters. In contrast, non-deterministic models like artificial neural networks (ANNs) can show variability in their results due to factors such as random weight initialization. ANNs often require multiple training iterations with different initializations or data subsets. To improve reliability, the results from these various training runs can be combined, typically by calculating statistical measures like the mean, which offers a more consistent representation of the model's performance or standard deviation, which represent the variability across the trained models.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc832c",
   "metadata": {},
   "source": [
    "An example of the use of this function can be seen in the following line:\n",
    "\n",
    "```Julia\n",
    "fit!(model, trainingInputs, trainingTargets);\n",
    "```\n",
    "\n",
    "As can be seen, the first argument of this function is the model, the second is an array of inputs, and the third is a vector of desired outputs. It is important to realise that this parameter with the desired outputs is not an array like in the case of ANNs but a vector whose each element will correspond to the label associated to that pattern, and can be of any type: integer, string, etc. The main reason for this is that there are some models that do not accept desired outputs with the one-hot-encoding.\n",
    "\n",
    "An important issue to consider is the layout of the data to be used. As has been shown in previous assignments, the patterns must be arranged in columns to train an ANN, being each row an attribute. Outside the world of ANNs, and therefore with the rest of the techniques to be used in this course, the patterns are usually assumed to be arranged in rows, and therefore each column in the input matrix corresponds to an attribute, being a much more intuitive way.\n",
    "\n",
    "### Question\n",
    "\n",
    "Which condition must the matrix of inputs and the vector of desired outputs passed as an argument to this function fulfil?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ed4cd",
   "metadata": {},
   "source": [
    "`The main condition is that the data must be correctly formatted. If we have an input matrix with dimensions (m, n), where m represents the number of samples and n is the number of features or input variables, then the output vector must have dimensions (1, m), providing one output value for each input sample.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8087b",
   "metadata": {},
   "source": [
    "Finally, once the model has been trained, it can be used to make predictions. This is done by means of the predict function. An example of its use is shown below:\n",
    "\n",
    "```Julia\n",
    "testOutputs = predict(model, testInputs);\n",
    "```\n",
    "\n",
    "The model being used is an in-memory structure with different fields, and it can be very useful to look up the contents of these fields. To see which fields each model has, you can write the following:\n",
    "\n",
    "```Julia\n",
    "println(keys(model));\n",
    "```\n",
    "\n",
    "Depending on the type of model, there will be different fields. For example, for a kNN, the following fields, among others, could be consulted:\n",
    "\n",
    "```Julia\n",
    "model.n_neighbors\n",
    "model.metric\n",
    "model.weights\n",
    "```\n",
    "\n",
    "For an SVM, some other interesting fields could be the following:\n",
    "\n",
    "```Julia\n",
    "model.C\n",
    "model.support_vectors_\n",
    "model.support_\n",
    "model.support_\n",
    "```\n",
    "\n",
    "In the case of an SVM, a particularly interesting function is `decision_function`, which returns the distances to the hyperplane of the passed patterns. This is useful, for example, to implement a \"one-against-all\" strategy to perform multi-class classification. An example of the use of this function is shown below:\n",
    "\n",
    "```Julia\n",
    "distances = decision_function(model, inputs);\n",
    "```\n",
    "\n",
    "### Question\n",
    "\n",
    "In the case of using decision trees or kNN, a corresponding function is not necessary to perform the \"one-against-all\" strategy, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e501314",
   "metadata": {},
   "source": [
    "`This is because, in contrast to algorithms like ANN, decision trees and k-nearest neighbors can naturally address multi-class classification problems.`\n",
    "\n",
    "`These models can directly perform a multiclass classification. The one-against all strategy is used with binary classification models (for example, the SVM, or ANN with sigmoid activation function).`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca345045",
   "metadata": {},
   "source": [
    "However, the SVM implementation in the Scikit-Learn library already allows multi-class classification, so it is not necessary to use a \"one-against-all\" strategy for these cases.\n",
    "\n",
    "Finally, it should be noted that these models usually receive pre-processed inputs and outputs, with the most common pre-processing being the normalisation already described in a previous assignment. Therefore, the developed normalisation functions should also be used on the data to be used by these models.\n",
    "\n",
    "In this assignment, you are asked to develop a function called ```modelCrossValidation``` based on the functions developed in previous assignments that allows to validate models in the selected classification problem using the three techniques described here.\n",
    "\n",
    "This function should perform cross-validation and use the metrics deemed most appropriate for the specific problem. This cross-validation can be done by modifying the code developed in the previous assignment.\n",
    "\n",
    "This function must receive the following parameters:\n",
    "\n",
    "- Algorithm to be trained, among the 4 used in this course, together with its parameter. The most important parameters to specify for each technique are:\n",
    "    </br>\n",
    "    \n",
    "    - ANN\n",
    "        - Architecture (number of hidden layers and number of neurons in each hidden layer) and transfer funtion in each layer. In \"shallow\" networks such as those used in this course, the transfer function has less impact, so a standard one, shuch as `tansig` or `logsig`, can be used.\n",
    "        - Learning rate\n",
    "        - Ratio of patterns used for validation\n",
    "        - Number of consecutive iterations without improving the validation loss to stop the process\n",
    "        - Number of times each ANN is trained.\n",
    "        \n",
    "        ### Question\n",
    "        \n",
    "        Why should a linear transfer function not be used for neurons in the hidden layers?\n",
    "        \n",
    "        `Using a linear transfer function in the hidden layers limits the network’s expressive power. When a linear function is used in these layers, the network’s output remains a linear transformation of the input, regardless of the depth of the network. As a result, it’s incapable of capturing non-linear patterns in the data.`\n",
    "        \n",
    "        `Instead, non-linear transfer functions like ReLU or sigmoid are preferred, as they enable the network to represent complex, non-linear relationships, thus enhancing its learning capability.`\n",
    "        \n",
    "        ### Question\n",
    "        \n",
    "        The other models do not have the number of times to train them as a parameter. Why? If you train several times, Which statistical properties will the results of these trainings have?\n",
    "\n",
    "        `Unlike neural networks, the other models in question are deterministic and non-iterative, meaning they don’t require repeated training over epochs. These models don’t perform iterative parameter updates and aren’t trained over multiple epochs.`\n",
    "        \n",
    "       `Training these deterministic models multiple times on the same dataset with the same parameters will yield identical results each time. This consistency means the results have a standard deviation of 0. Thus, during cross-validation, these models only need to be trained once per fold, unlike neural networks which may require multiple runs due to their iterative nature.`\n",
    "    </br>  \n",
    "    \n",
    "    - SVM\n",
    "        - Kernel (and kernel-specific parameters)\n",
    "        - C\n",
    "        \n",
    "    </br>  \n",
    "    - Decision trees\n",
    "        - Maximum tree depth\n",
    "        \n",
    "    </br>  \n",
    "    - kNN\n",
    "        - k (number of neighbours to be considered)\n",
    "\n",
    "    </br>        \n",
    "- Already standardised input and desired outputs matrices.\n",
    "    </br>  \n",
    "\n",
    "    - As stated above, the desired outputs must be indicated as a vector where each element is the label corresponding to each pattern (therefore, of type `Array{Any,1}`). In the case of ANN training, the desired outputs shall be encoded as done in previous assignments.\n",
    "    \n",
    "    ### Question\n",
    "    \n",
    "    Has it been necessary to standardise the desired outputs? Why?\n",
    "    \n",
    "    `It’s  not necessary to standardize target outputs in machine learning models. The target outputs, which are often categorical labels in classification tasks, do not require scaling, as they are not treated as continuous values by the model. In classification, the outputs indicate class membership rather than numerical values that need to be on a common scale. For instance, one-hot encoding is typically used to represent each class as a probability distribution in the range [0, 1]. This encoding provides a straightforward representation that doesn’t require further standardization. However, in regression tasks, where output values can vary widely, standardizing the outputs can sometimes help the model by reducing variability, especially if the output range is large.`\n",
    "    \n",
    "    </br>  \n",
    "    - As previously described, in the case of using techniques such as SVM, decision trees or kNN, the one-hot-encoding configuration will not be used. In these cases, the `confusionMatrix` function developed in a previous assignment will be used to calculate the metrics, which accepts as input two vectors (outputs and desired outputs) of type `Array{Any,1}`.\n",
    "    \n",
    "    </br>  \n",
    "- Cross-validation indices. It is important to note that, as in the previous assignment, the partitioning of the patterns in each fold need to be done outside this function, because this allows this same partitioning to be used then training other models. In this way, cross-validation is performed with the same data and the same partitions in all classes.\n",
    "\n",
    "Since most of the code will be the same, do not develop 4 different functions, one for each model, but only one function. Inside it, at the time of generation the model in each fold, and depending on the model, the following changes should be made:\n",
    "\n",
    "- If the model is an ANN, the desired outputs shall be encoded by means of the code developed in previous assignments. As this model is non-deterministic, it will be nevessary to make a new loop to train several ANNs, splitting the training data into training and validation (if validation set is used) and calling the function defined in previous assignments to create and traing an ANN.\n",
    "\n",
    "- If the model is not an ANN, the code that trains the model shall be developed. This code shall be the same for each of the rematining 3 types of models (SVM, decision trees, and KNN), with the line where the model is called being the only difference.\n",
    "\n",
    "In turn, this function should return, at least, the values for the selected metrics. Once this function has been developed, the experimental part of the assignment begins. The objective is to determine which model with a specific combination of hyperparameters offers the best results, for which the above function will be run for each of the 4 types of models, and for each model it will be run with different values in its hyperparameters.\n",
    "\n",
    "- The results obtained should be documented in the report to be produced, for which it will be useful to show the results in tabular and/or graphical form.\n",
    "\n",
    "- When it comes to displaying a confusion matrix in the report, an important question is which one to show given that a lot of trainings have been performed. The cross-validation technique does not generate a final model, but allows comparing different algorithms and configurations to choose the model or parameter configuration that returns the best results. Once chosen, it is necessary to train a \"final\" model from scratch by using all the patterns as the training set, that is, without separating patterns for testing. In this way, the performance of this model and configuration is expected to be slightly higher than that obtained through cross-validation, since more patterns have been used to train it. This is the final model that would be used in production, and from which a confusion matrix can be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01ed123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg;\n",
    "using Pkg\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"ScikitLearn\")\n",
    "Pkg.add(\"OptimizationOptimisers\");\n",
    "using ScikitLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f90bdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149-element PooledArrays.PooledVector{String15, UInt32, Vector{UInt32}}:\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " \"Iris-setosa\"\n",
       " ⋮\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\"\n",
       " \"Iris-virginica\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Random\n",
    "using Statistics\n",
    "using Flux\n",
    "\n",
    "iris_df = CSV.read(\"./data/iris/iris.data\", DataFrame)\n",
    "\n",
    "inputs = Matrix(iris_df[:,1:4])\n",
    "targets = iris_df[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb165667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "include(\"functionsLibrary.jl\")\n",
    "\n",
    "Random.seed!(888);\n",
    "sizeDataset = size(inputs, 1)\n",
    "println(sizeDataset)\n",
    "(trainIndex, testIndex) = holdOut(sizeDataset, 0.2)\n",
    "\n",
    "trainInputs         = convert(Array{Real}, inputs[trainIndex, :])\n",
    "trainTargets        = targets[trainIndex, :]\n",
    "trainTargets        = trainTargets[:, 1]\n",
    "\n",
    "testInputs          = convert(Array{Real}, inputs[testIndex, :])\n",
    "testTargets         = targets[testIndex, :]\n",
    "testTargets         = testTargets[:, :] # Convert to vector\n",
    "\n",
    "trainingDataset     = (trainInputs, trainTargets);\n",
    "testDataset         = (testInputs, testTargets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9ba1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsNormalized            = normalizeMinMax(convert(Array{Real}, inputs));\n",
    "trainInputsNormalized       = normalizeMinMax(convert(Array{Real}, trainInputs));\n",
    "testInputsNormalized        = normalizeMinMax(convert(Array{Real}, testInputs));\n",
    "\n",
    "import Random\n",
    "XValVector          = crossvalidation(trainTargets, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d6f259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant Main.SVC. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant Main.DecisionTreeClassifier. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant Main.KNeighborsClassifier. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    }
   ],
   "source": [
    "@sk_import svm: SVC;\n",
    "@sk_import tree: DecisionTreeClassifier;\n",
    "@sk_import neighbors: KNeighborsClassifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17e6c492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelCrossValidation (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function modelCrossValidation(modelType::Symbol,\n",
    "    modelHyperparameters::Dict,\n",
    "    inputs::AbstractArray{<:Real,2},\n",
    "    targets::AbstractArray{<:Any,1},\n",
    "    crossValidationIndices::Array{Int64,1}) \n",
    "\n",
    "\n",
    "    @assert (length(crossValidationIndices) == size(targets, 1) == size(inputs, 1))\n",
    "\n",
    "    if modelType == :ANN\n",
    "        topologyANN             = modelHyperparameters[\"topology\"]\n",
    "        transferFunctionsANN    = modelHyperparameters[\"transferFunctions\"]\n",
    "        maxEpochsANN            = modelHyperparameters[\"maxEpochs\"]\n",
    "        maxEpochsValANN         = modelHyperparameters[\"maxEpochsVal\"]\n",
    "        learningRateANN         = modelHyperparameters[\"learningRate\"]\n",
    "        validationRatioANN      = modelHyperparameters[\"validationRatio\"]\n",
    "\n",
    "        targetsANN = oneHotEncoding(targets)\n",
    "\n",
    "        trainingDatasetANN = (inputs, targetsANN)\n",
    "\n",
    "        return trainClassANN(topologyANN, trainingDatasetANN, crossValidationIndices, transferFunctions=transferFunctionsANN, maxEpochs=maxEpochsANN, maxEpochsVal=maxEpochsValANN,\n",
    "                        learningRate=learningRateANN)\n",
    "\n",
    "\n",
    "    elseif modelType == :kNN\n",
    "        k = modelHyperparameters[\"k\"]\n",
    "        model = KNeighborsClassifier(k);\n",
    " \n",
    "    elseif modelType == :SVM\n",
    "        \n",
    "        # Extracting data from dictionary\n",
    "        kernelSVM               = modelHyperparameters[\"kernel\"]\n",
    "        degreeSVM               = modelHyperparameters[\"degree\"]\n",
    "        gammaSVM                = modelHyperparameters[\"gamma\"]\n",
    "        cSVM                    = modelHyperparameters[\"c\"]\n",
    "        # Model\n",
    "        model = SVC(kernel=kernelSVM, degree=degreeSVM, gamma=gammaSVM, C=cSVM);\n",
    "\n",
    "    elseif modelType == :tree\n",
    "        # Extracting data from dictionary\n",
    "        treeDepth  = modelHyperparameters[\"depth\"]\n",
    "        # Model\n",
    "        model = DecisionTreeClassifier(max_depth=treeDepth, random_state=1);\n",
    "\n",
    "    end\n",
    "    numFolds = maximum(crossValidationIndices);\n",
    "\n",
    "    numMetrics = 7;\n",
    "    metrics = Matrix{Float64}(undef, numFolds, numMetrics);\n",
    "\n",
    "    sensivity   =   zeros(Float64, numFolds)\n",
    "    specificity =   zeros(Float64, numFolds)\n",
    "    PPV         =   zeros(Float64, numFolds)\n",
    "    NPV         =   zeros(Float64, numFolds)\n",
    "    Fscore      =   zeros(Float64, numFolds)\n",
    "\n",
    "    accuracyVector      = zeros(Float64, numFolds)\n",
    "    errorRateVector     = zeros(Float64, numFolds)\n",
    "    recallVector        = zeros(Float64, numFolds)\n",
    "    specificityVector   = zeros(Float64, numFolds)\n",
    "    PPVVector           = zeros(Float64, numFolds)\n",
    "    NPVVector           = zeros(Float64, numFolds)\n",
    "    FscoreVector        = zeros(Float64, numFolds)\n",
    "\n",
    "    globalCMatrix = zeros(Float64, size(targets, 2), size(targets, 2))\n",
    "    \n",
    "\n",
    "    for numFold in 1:numFolds\n",
    "        trainingInputs  = inputs[crossValidationIndices.!=  numFold,:]; \n",
    "        valInputs   = inputs[crossValidationIndices.==  numFold,:];\n",
    "        \n",
    "        trainingTargets = targets[crossValidationIndices.!= numFold,:];\n",
    "        valTargets  = targets[crossValidationIndices.== numFold,:];\n",
    "\n",
    "        fit!(model, trainingInputs, trainingTargets)\n",
    "\n",
    "        valOutputs = predict(model, valInputs)\n",
    "\n",
    "        (accuracyVal, errorRateVal, sensivityVal, specificityVal, \n",
    "        PPVVal, NPVVal, FscoreVal, globalCMatrix) = confusionMatrix(valOutputs, valTargets[:,1])\n",
    "        \n",
    "        accuracyVector[numFold]     = accuracyVal\n",
    "        errorRateVector[numFold]    = errorRateVal\n",
    "        recallVector[numFold]       = sensivityVal\n",
    "        specificityVector[numFold]  = specificityVal\n",
    "        PPVVector[numFold]          = PPVVal\n",
    "        NPVVector[numFold]             = NPVVal\n",
    "        FscoreVector[numFold]       = FscoreVal\n",
    "\n",
    "\n",
    "    end;\n",
    "\n",
    "    accuracyMean    = mean(accuracyVector)\n",
    "    errorRateMean   = mean(errorRateVector)\n",
    "    recallMean      = mean(recallVector)\n",
    "    specificityMean = mean(specificityVector)\n",
    "    PPVMean         = mean(PPVVector)\n",
    "    NPVMean         = mean(NPVVector)\n",
    "    FscoreMean      = mean(FscoreVector)\n",
    "    cMatrixMean     = mean(globalCMatrix)\n",
    "\n",
    "    return ([accuracyMean, errorRateMean, recallMean, specificityMean, PPVMean, NPVMean, FscoreMean], globalCMatrix)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15f54ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainClassANN (generic function with 4 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"functionsLibrary.jl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ff0048",
   "metadata": {},
   "source": [
    "##### TEST FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "830ffc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.107021995>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.14986682>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.13398531>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.16314691>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.10768156>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.1391544>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.15184768>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.13486607>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.10926644>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.10308813>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.14791475>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.13551979>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.13784263>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.14962652>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.109253414>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.13443087>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.108466215>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.13275594>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.094320476>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.086013846>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.06230915>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.07938973>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.07868914>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.07190178>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.06475118>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.07258343>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.07004556>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.065400474>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.04804859>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n",
      "Stop criteria:\n",
      "numEpoch 1000<maxEpochs 1000\n",
      "trainingLoss 0.045623723>minLoss 0.0\n",
      "numEpochsValidation 1<maxEpochsVal 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/djove/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "ANNdict1     = Dict(\"topology\" => [26,8], \"transferFunctions\" => [σ, σ], \"maxEpochs\" => 1000, \"maxEpochsVal\" => 20, \"learningRate\" => 0.01, \"validationRatio\" => 0.3)\n",
    "KNNdict1     = Dict(\"k\" => 5)\n",
    "SVMdict1     = Dict(\"kernel\" => \"rbf\", \"degree\" =>3, \"gamma\" => 2, \"c\" => 1)\n",
    "treedict1    = Dict(\"depth\" => 4)\n",
    "\n",
    "ANNdict2     = Dict(\"topology\" => [10,10], \"transferFunctions\" => [σ, σ], \"maxEpochs\" => 1000, \"maxEpochsVal\" => 20, \"learningRate\" => 0.01, \"validationRatio\" => 0.3)\n",
    "KNNdict2     = Dict(\"k\" => 7)\n",
    "SVMdict2     = Dict(\"kernel\" => \"rbf\", \"degree\" =>4, \"gamma\" => 2, \"c\" => 1)\n",
    "treedict2    = Dict(\"depth\" => 6)\n",
    "\n",
    "ANNdict3     = Dict(\"topology\" => [4,3], \"transferFunctions\" => [σ, σ], \"maxEpochs\" => 1000, \"maxEpochsVal\" => 20, \"learningRate\" => 0.01, \"validationRatio\" => 0.3)\n",
    "KNNdict3     = Dict(\"k\" => 3)\n",
    "SVMdict3     = Dict(\"kernel\" => \"rbf\", \"degree\" =>2, \"gamma\" => 2, \"c\" => 1)\n",
    "treedict3    = Dict(\"depth\" => 3)\n",
    "\n",
    "modelANN1 = modelCrossValidation(:ANN, ANNdict1, trainInputsNormalized, trainTargets, XValVector)\n",
    "modelkNN1 = modelCrossValidation(:kNN, KNNdict1, trainInputsNormalized, trainTargets, XValVector);\n",
    "modelSVM1 = modelCrossValidation(:SVM, SVMdict1, trainInputsNormalized, trainTargets, XValVector);\n",
    "modelTree1 = modelCrossValidation(:tree, treedict1, trainInputsNormalized, trainTargets, XValVector);\n",
    "\n",
    "modelANN2 = modelCrossValidation(:ANN, ANNdict2, trainInputsNormalized, trainTargets, XValVector)\n",
    "modelkNN2 = modelCrossValidation(:kNN, KNNdict2, trainInputsNormalized, trainTargets, XValVector);\n",
    "modelSVM2 = modelCrossValidation(:SVM, SVMdict2, trainInputsNormalized, trainTargets, XValVector);\n",
    "modelTree2 = modelCrossValidation(:tree, treedict2, trainInputsNormalized, trainTargets, XValVector);\n",
    "\n",
    "modelANN3 = modelCrossValidation(:ANN, ANNdict3, trainInputsNormalized, trainTargets, XValVector)\n",
    "modelkNN3 = modelCrossValidation(:kNN, KNNdict3, trainInputsNormalized, trainTargets, XValVector);\n",
    "modelSVM3 = modelCrossValidation(:SVM, SVMdict3, trainInputsNormalized, trainTargets, XValVector);\n",
    "modelTree3 = modelCrossValidation(:tree, treedict3, trainInputsNormalized, trainTargets, XValVector);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e1e2d",
   "metadata": {},
   "source": [
    "##### COMPARE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d93a7404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelComparison (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function modelComparison(modelANN::Tuple{Vector{Float64}, Vector{Float64}}, modelkNN::Tuple{Vector{Float64}, Matrix{Float64}},\n",
    "    modelSVM::Tuple{Vector{Float64}, Matrix{Float64}}, modelTree::Tuple{Vector{Float64}, Matrix{Float64}})\n",
    "       \n",
    "       accuracyIndex =     1\n",
    "       errorRateIndex =    2\n",
    "       recallIndex =       3\n",
    "       specificityIndex =  4\n",
    "       PPVIndex =          5\n",
    "       NPVIndex =          6\n",
    "       FscoreIndex =       7\n",
    "   \n",
    "   \n",
    "       println(\"                   >>>   MODEL COMPARISON   <<< \")\n",
    "       println(\" \")\n",
    "       println(\"                       ANN         kNN         SVM         TREE    \")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"Accuracy:             $(round(modelANN[1][accuracyIndex], digits=3))       $(round(modelkNN[1][accuracyIndex], digits=3))        $(round(modelSVM[1][accuracyIndex], digits=3))        $(round(modelTree[1][accuracyIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"Error rate:           $(round(modelANN[1][errorRateIndex], digits=3))       $(round(modelkNN[1][errorRateIndex], digits= 3))        $(round(modelSVM[1][errorRateIndex], digits=3))        $(round(modelTree[1][errorRateIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"Recall:               $(round(modelANN[1][recallIndex], digits=3))       $(round(modelkNN[1][recallIndex], digits=3))        $(round(modelSVM[1][recallIndex], digits=3))        $(round(modelTree[1][recallIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"Specificity::         $(round(modelANN[1][specificityIndex], digits=3))       $(round(modelkNN[1][specificityIndex], digits=3))        $(round(modelSVM[1][specificityIndex], digits=3))        $(round(modelTree[1][specificityIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"PPV::                 $(round(modelANN[1][PPVIndex], digits=3))       $(round(modelkNN[1][PPVIndex], digits=3))        $(round(modelSVM[1][PPVIndex], digits=3))        $(round(modelTree[1][PPVIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"NPV::                 $(round(modelANN[1][NPVIndex], digits=3))       $(round(modelkNN[1][NPVIndex], digits=3))        $(round(modelSVM[1][NPVIndex], digits=3))        $(round(modelTree[1][NPVIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\"Fscore::              $(round(modelANN[1][FscoreIndex], digits=3))       $(round(modelkNN[1][FscoreIndex], digits=3))        $(round(modelSVM[1][FscoreIndex], digits=3))        $(round(modelTree[1][FscoreIndex], digits=3))\")\n",
    "       println(\"---------------------------------------------------------------------\")\n",
    "       println(\" \")\n",
    "   end\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd658016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   >>>   MODEL COMPARISON   <<< \n",
      " \n",
      "                       ANN         kNN         SVM         TREE    \n",
      "---------------------------------------------------------------------\n",
      "Accuracy:             0.922       0.946        0.966        0.932\n",
      "---------------------------------------------------------------------\n",
      "Error rate:           0.078       0.054        0.034        0.068\n",
      "---------------------------------------------------------------------\n",
      "Recall:               1.0       0.942        0.942        0.917\n",
      "---------------------------------------------------------------------\n",
      "Specificity::         1.0       0.988        0.988        0.962\n",
      "---------------------------------------------------------------------\n",
      "PPV::                 1.0       0.967        0.983        0.925\n",
      "---------------------------------------------------------------------\n",
      "NPV::                 1.0       0.976        0.978        0.965\n",
      "---------------------------------------------------------------------\n",
      "Fscore::              1.0       0.952        0.957        0.918\n",
      "---------------------------------------------------------------------\n",
      " \n",
      "                   >>>   MODEL COMPARISON   <<< \n",
      " \n",
      "                       ANN         kNN         SVM         TREE    \n",
      "---------------------------------------------------------------------\n",
      "Accuracy:             0.93       0.955        0.966        0.923\n",
      "---------------------------------------------------------------------\n",
      "Error rate:           0.07       0.045        0.034        0.077\n",
      "---------------------------------------------------------------------\n",
      "Recall:               1.0       0.942        0.942        0.892\n",
      "---------------------------------------------------------------------\n",
      "Specificity::         1.0       0.988        0.988        0.962\n",
      "---------------------------------------------------------------------\n",
      "PPV::                 1.0       0.967        0.983        0.925\n",
      "---------------------------------------------------------------------\n",
      "NPV::                 1.0       0.976        0.978        0.954\n",
      "---------------------------------------------------------------------\n",
      "Fscore::              1.0       0.952        0.957        0.904\n",
      "---------------------------------------------------------------------\n",
      " \n",
      "                   >>>   MODEL COMPARISON   <<< \n",
      " \n",
      "                       ANN         kNN         SVM         TREE    \n",
      "---------------------------------------------------------------------\n",
      "Accuracy:             0.947       0.946        0.966        0.93\n",
      "---------------------------------------------------------------------\n",
      "Error rate:           0.053       0.054        0.034        0.07\n",
      "---------------------------------------------------------------------\n",
      "Recall:               1.0       0.942        0.942        0.975\n",
      "---------------------------------------------------------------------\n",
      "Specificity::         1.0       0.988        0.988        0.95\n",
      "---------------------------------------------------------------------\n",
      "PPV::                 1.0       0.967        0.983        0.913\n",
      "---------------------------------------------------------------------\n",
      "NPV::                 1.0       0.976        0.978        0.989\n",
      "---------------------------------------------------------------------\n",
      "Fscore::              1.0       0.952        0.957        0.937\n",
      "---------------------------------------------------------------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "modelComparison(modelANN1, modelkNN1, modelSVM1, modelTree1)\n",
    "modelComparison(modelANN2, modelkNN2, modelSVM2, modelTree2)\n",
    "modelComparison(modelANN3, modelkNN3, modelSVM3, modelTree3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f43ef99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trainAnyModel (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function trainAnyModel(modelType::Symbol,\n",
    "    modelHyperparameters::Dict,\n",
    "    inputs::AbstractArray{<:Real,2},\n",
    "    targets::AbstractArray{<:Any,1})\n",
    "\n",
    "     @assert (size(targets, 1) == size(inputs, 1))\n",
    "\n",
    "    if modelType == :ANN\n",
    "        topologyANN             = modelHyperparameters[\"topology\"]\n",
    "        transferFunctionsANN    = modelHyperparameters[\"transferFunctions\"] # What if there is an empty field?\n",
    "        maxEpochsANN            = modelHyperparameters[\"maxEpochs\"]\n",
    "        maxEpochsValANN         = modelHyperparameters[\"maxEpochsVal\"]\n",
    "        learningRateANN         = modelHyperparameters[\"learningRate\"]\n",
    "        validationRatioANN      = modelHyperparameters[\"validationRatio\"]\n",
    "\n",
    "        targetsANN = oneHotEncoding(targets) \n",
    "\n",
    "        trainingDatasetANN = (inputs, targetsANN)\n",
    "\n",
    "        model = trainClassANN(topologyANN, trainingDatasetANN, transferFunctions=transferFunctionsANN, maxEpochs=maxEpochsANN, maxEpochsVal=maxEpochsValANN,\n",
    "                        learningRate=learningRateANN)[1]\n",
    "\n",
    "        return model\n",
    " \n",
    " elseif modelType == :kNN\n",
    "        k = modelHyperparameters[\"k\"]\n",
    "        model = KNeighborsClassifier(k);\n",
    "\n",
    "    elseif modelType == :SVM\n",
    "        \n",
    "        kernelSVM               = modelHyperparameters[\"kernel\"]\n",
    "        degreeSVM               = modelHyperparameters[\"degree\"]\n",
    "        gammaSVM                = modelHyperparameters[\"gamma\"]\n",
    "        cSVM                    = modelHyperparameters[\"c\"]\n",
    "        # Model\n",
    "        model = SVC(kernel=kernelSVM, degree=degreeSVM, gamma=gammaSVM, C=cSVM);\n",
    "\n",
    "    elseif modelType == :tree\n",
    "        treeDepth  = modelHyperparameters[\"depth\"]\n",
    "        model = DecisionTreeClassifier(max_depth=treeDepth, random_state=1);\n",
    "\n",
    "    end\n",
    "\n",
    "    fit!(model, inputs, targets)\n",
    "\n",
    "    return model\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c521f7b",
   "metadata": {},
   "source": [
    "In the comparison chunk of code, we can see that the model with the best metrics is the second SVM.  Therefore, we'll train the definitive model with that configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839db4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23af65f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, degree=4, gamma=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1, degree=4, gamma=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PyObject SVC(C=1, degree=4, gamma=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bestModel = trainAnyModel(:SVM, SVMdict2, trainInputsNormalized, trainTargets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "456ac6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Accuracy : 0.967\n",
      "Error rate: 0.033\n",
      "Recall: 1.0\n",
      "Specificity: 1.0\n",
      "Precision: 1.0\n",
      "Negative Predictive value: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "testOutputs = predict(bestModel, testInputsNormalized)\n",
    "printConfusionMatrix(testOutputs, testTargets[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a7ded7",
   "metadata": {},
   "source": [
    "### Learn Julia\n",
    "\n",
    "In this assignment, it is necessary to pass parameters which are dependent on the model. To do this, the simplest way is to create a variable of type Dictionary (actually the type is `Dict`) which works in a similar way to Python. For example, to specify the parameters of an SVM, you could create a variable as follows:\n",
    "\n",
    "```Julia\n",
    "parameters = Dict(\"kernel\" => \"rbf\", \"degree\" => 3, \"gamma\" => 2, \"C\" => 1);\n",
    "```\n",
    "\n",
    "Another way of defining such a variable could be the following:\n",
    "\n",
    "```Julia\n",
    "parameters = Dict();\n",
    "\n",
    "parameters[\"kernel\"] = \"rbf\";\n",
    "parameters[\"kernelDegree\"] = 3;\n",
    "parameters[\"kernelGamma\"] = 2;\n",
    "parameters[\"C\"] = 1;\n",
    "```\n",
    "\n",
    "Once inside the function to be developed, the model parameters can be used to create the model objet as follows:\n",
    "\n",
    "```Julia\n",
    "model = SVC(kernel=parameters[\"kernel\"], \n",
    "    degree=parameters[\"kernelDegree\"], \n",
    "    gamma=parameters[\"kernelGamma\"], \n",
    "    C=parameters[\"C\"]);\n",
    "```\n",
    "\n",
    "In the same way, something similar could be done for decision trees and kNN.\n",
    "\n",
    "Another type of Julia that may be interesting for this assignment is the `Symbol` type. An object of this type can be any symbol you want, simply by typing its name after a colon (\":\"). In this practice, you can use it to indicate which model you want to train, for example `:ANN`, `:SVM`, `:DecisionTree` or `:kNN`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
